{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading with Numba\n",
    "\n",
    "<span style=\"color: red\">**WARNING**</span>: *Due to the CPU restrictions on notebook execution on Binder, the benefits of multithreading are going to be erratic.  The code in this notebook will run on Binder, but for reasonable benchmarks, you should download and run this notebook on your own system.*\n",
    "\n",
    "Numba supports several approaches to multithreading:\n",
    "\n",
    "* Automatic multithreading of array expressions and reductions\n",
    "* Explicit multithreading of loops with `prange()`\n",
    "* External multithreading with tools like concurrent.futures or Dask.\n",
    "\n",
    "The first two options make use of the *ParallelAccelerator* optimization pass (contributed by Intel) in Numba.  ParallelAccelerator is only supported on 64-bit platforms, and is not available for Python 2.7 on Windows.  It is also only effective when compiling in nopython mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Multithreading\n",
    "\n",
    "NumPy array expressions have a significant amount of implied parallelism, as operations are broadcast independently over the input elements.  ParallelAccelerator can identify this parallelism and automatically distribute it over several threads.  All we need to do is enable the parallelization pass with `parallel=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQRT_2PI = np.sqrt(2 * np.pi)\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def gaussians(x, means, widths):\n",
    "    '''Return the value of gaussian kernels.\n",
    "    \n",
    "    x - location of evaluation\n",
    "    means - array of kernel means\n",
    "    widths - array of kernel widths\n",
    "    '''\n",
    "    n = means.shape[0]\n",
    "    result = np.exp( -0.5 * ((x - means) / widths)**2 ) / widths\n",
    "    return result / SQRT_2PI / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.11349524e-06, 2.84893723e-07, 6.58273284e-18, ...,\n",
       "       9.28276952e-07, 1.39785359e-06, 2.72504176e-18])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = np.random.uniform(-1, 1, size=1000000)\n",
    "widths = np.random.uniform(0.1, 0.3, size=1000000)\n",
    "\n",
    "gaussians(0.4, means, widths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the effect of multiple CPUs, we can compare to the case where ParallelAccelerator disabled. Noting that decorators are functions that transform other functions, we can call `jit` as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.8 ms ± 463 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "5.89 ms ± 1.01 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "gaussians_nothread = jit(nopython=True)(gaussians.py_func)\n",
    "\n",
    "%timeit gaussians_nothread(0.4, means, widths)\n",
    "%timeit gaussians(0.4, means, widths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the performance to the uncompiled NumPy array evaluation using the `.py_func` attribute to get the original Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ms ± 1.28 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gaussians.py_func(0.4, means, widths) # compare to pure NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance ratio depends on the number of CPUs in your system, but the multithreaded version is definitely faster than the single threaded version.\n",
    "\n",
    "ParallelAccelerator can also handle reductions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def kde(x, means, widths):\n",
    "    '''Return the value of gaussian kernels.\n",
    "    \n",
    "    x - location of evaluation\n",
    "    means - array of kernel means\n",
    "    widths - array of kernel widths\n",
    "    '''\n",
    "    n = means.shape[0]\n",
    "    result = np.exp( -0.5 * ((x - means) / widths)**2 ) / widths\n",
    "    return result.mean() / SQRT_2PI\n",
    "\n",
    "kde_nothread = jit(nopython=True)(kde.py_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.8 ms ± 1.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "4.4 ms ± 935 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit kde_nothread(0.4, means, widths)\n",
    "%timeit kde(0.4, means, widths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading with `prange()`\n",
    "\n",
    "There are other situations where you would like multithreading, but do not have a straightforward array expression.  In those cases, using `prange()` in a for loop indicates to ParallelAccelerator that this is a loop where each iteration is independent of the other and can be executed in parallel.\n",
    "\n",
    "For example, we might want to run many Monte Carlo trials in a row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Serial version\n",
    "@jit(nopython=True)\n",
    "def monte_carlo_pi_serial(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / nsamples\n",
    "\n",
    "# Parallel version\n",
    "@jit(nopython=True, parallel=True)\n",
    "def monte_carlo_pi_parallel(nsamples):\n",
    "    acc = 0\n",
    "    # Only change is here\n",
    "    for i in numba.prange(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `prange()` is automatically handling the reduction variable `acc` in a thread-safe way for you.  We are also relying on Numba to automatically initialize the random number generator in each thread independently.\n",
    "\n",
    "You can also have each thread in a `prange()` modify a separate element in an output array, but more general race conditions are not automatically resolved by ParallelAccelerator.  Be careful!\n",
    "\n",
    "Let's see how fast these two implementations are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.5 s, sys: 3.79 ms, total: 4.5 s\n",
      "Wall time: 4.48 s\n",
      "CPU times: user 9.17 s, sys: 30.2 ms, total: 9.2 s\n",
      "Wall time: 1.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.14171747"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time monte_carlo_pi_serial(int(4e8))\n",
    "%time monte_carlo_pi_parallel(int(4e8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parallel version saturates all the CPUs once the initial compilation finishes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
